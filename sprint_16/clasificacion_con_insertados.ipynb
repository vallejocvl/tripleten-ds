{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicialización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "2b1861ea-c3e0-4698-b05b-5c58897896c5"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrena un modelo de regresión logística mediante insertados. Imprime el valor de exactitud para el conjunto de entrenamiento.\n",
    "\n",
    "Calcular los insertados de BERT lleva mucho tiempo (si no estás usando una GPU), por lo que te sugerimos tomar solo 200 elementos aleatorios del conjunto. Los elementos se guardan en el archivo imdb_reviews_200.tsv. Divídelos en conjuntos de entrenamiento y prueba en una proporción de 50:50 para una prueba correcta.\n",
    "\n",
    "El objetivo se almacena en la variable pos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sample_size = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = pd.read_csv('/datasets/imdb_reviews_200.tsv', sep='\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento para BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "ids_list = []\n",
    "attention_mask_list = []\n",
    "\n",
    "max_length = 512\n",
    "\n",
    "for input_text in df_reviews.iloc[:max_sample_size]['review']:\n",
    "    ids = tokenizer.encode(input_text.lower(), add_special_tokens=True, truncation=True, max_length=max_length)\n",
    "    padded = np.array(ids + [0]*(max_length - len(ids)))\n",
    "    attention_mask = np.where(padded != 0, 1, 0)\n",
    "    ids_list.append(padded)\n",
    "    attention_mask_list.append(attention_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtener insertados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = transformers.BertConfig.from_pretrained('bert-base-uncased')\n",
    "model = transformers.BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 25    # por lo general, el tamaño del lote es igual a 100, pero lo podemos configurar en valores más bajos para reducir los requisitos de memoria\n",
    "\n",
    "embeddings = []\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Uso del dispositivo {device}.')\n",
    "model.to(device)\n",
    "\n",
    "for i in tqdm(range(len(ids_list) // batch_size)):\n",
    "    \n",
    "    ids_batch = torch.LongTensor(ids_list[batch_size*i:batch_size*(i+1)]).to(device)\n",
    "    attention_mask_batch = torch.LongTensor(attention_mask_list[batch_size*i:batch_size*(i+1)]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        batch_embeddings = model(ids_batch, attention_mask=attention_mask_batch)\n",
    "\n",
    "    embeddings.append(batch_embeddings[0][:,0,:].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate(embeddings)\n",
    "target = df_reviews.iloc[:max_sample_size]['pos']\n",
    "\n",
    "print(features.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrena y prueba tu modelo\n",
    "# < escribe tu código aquí  >"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
