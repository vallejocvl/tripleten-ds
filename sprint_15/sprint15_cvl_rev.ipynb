{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>¡Hola Carlos!</b>\n",
    "\n",
    "Mi nombre es Alejandro Abia y tengo el gusto de revisar tu proyecto.\n",
    "\n",
    "A continuación, encontrarás mis comentarios en celdas pintadas de tres colores (verde, amarillo y rojo), a manera de semáforo. Por favor, <b>no las borres ni muevas de posición</b> mientras dure el proceso de revisión.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Éxito</b> <a class=\"tocSkip\"></a>\n",
    "En celdas verdes encontrarás comentarios en relación a tus aciertos y fortalezas.\n",
    "</div>\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Atención</b> <a class=\"tocSkip\"></a>\n",
    "Utilizaré el color amarillo para llamar tu atención, expresar algo importante o compartirte alguna idea de valor.\n",
    "</div>\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>A resolver</b> <a class=\"tocSkip\"></a>\n",
    "En rojo emitiré aquellos puntos que podrían impedir que el proyecto se ejecute correctamente. No son errores, sino oportunidades importantes de mejora.\n",
    "</div>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Comentario estudiante</b> <a class=\"tocSkip\"></a>\n",
    "Si durante la revisión deseas dejarme algún comentario, por favor utiliza celdas azules como esta.\n",
    "</div>\n",
    "Tu proyecto será considerado aprobado cuando las observaciones en rojo hayan sido atendidas.  \n",
    "¡Empecemos!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripción del proyecto\n",
    "\n",
    "La compañía Sweet Lift Taxi ha recopilado datos históricos sobre pedidos de taxis en los aeropuertos. Para atraer a más conductores durante las horas pico, necesitamos predecir la cantidad de pedidos de taxis para la próxima hora. Construye un modelo para dicha predicción.\n",
    "\n",
    "La métrica RECM en el conjunto de prueba no debe ser superior a 48.\n",
    "\n",
    "## Instrucciones del proyecto.\n",
    "\n",
    "1. Descarga los datos y haz el remuestreo por una hora.\n",
    "2. Analiza los datos\n",
    "3. Entrena diferentes modelos con diferentes hiperparámetros. La muestra de prueba debe ser el 10% del conjunto de datos inicial.4. Prueba los datos usando la muestra de prueba y proporciona una conclusión.\n",
    "\n",
    "## Descripción de los datos\n",
    "\n",
    "Los datos se almacenan en el archivo `taxi.csv`. \t\n",
    "El número de pedidos está en la columna `num_orders`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar Librerias y DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'root_mean_squared_error' from 'sklearn.metrics' (/.venv/lib/python3.9/site-packages/sklearn/metrics/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m root_mean_squared_error, make_scorer\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'root_mean_squared_error' from 'sklearn.metrics' (/.venv/lib/python3.9/site-packages/sklearn/metrics/__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'datasets/taxi.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatasets/taxi.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mtail())\n",
      "File \u001b[0;32m/.venv/lib/python3.9/site-packages/pandas/io/parsers.py:610\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    605\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    606\u001b[0m     dialect, delimiter, delim_whitespace, engine, sep, defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m    607\u001b[0m )\n\u001b[1;32m    608\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 610\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/.venv/lib/python3.9/site-packages/pandas/io/parsers.py:462\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    459\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    461\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 462\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/.venv/lib/python3.9/site-packages/pandas/io/parsers.py:819\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwds:\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 819\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/.venv/lib/python3.9/site-packages/pandas/io/parsers.py:1050\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1046\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1047\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown engine: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (valid options are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmapping\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1048\u001b[0m     )\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;66;03m# error: Too many arguments for \"ParserBase\"\u001b[39;00m\n\u001b[0;32m-> 1050\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/.venv/lib/python3.9/site-packages/pandas/io/parsers.py:1867\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1864\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musecols\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musecols\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# open handles\u001b[39;00m\n\u001b[0;32m-> 1867\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open_handles\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/.venv/lib/python3.9/site-packages/pandas/io/parsers.py:1362\u001b[0m, in \u001b[0;36mParserBase._open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_handles\u001b[39m(\u001b[38;5;28mself\u001b[39m, src: FilePathOrBuffer, kwds: Dict[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;124;03m    Let the readers open IOHanldes after they are done with their potential raises.\u001b[39;00m\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1362\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1363\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1364\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1367\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1369\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/.venv/lib/python3.9/site-packages/pandas/io/common.py:642\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m         errors \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 642\u001b[0m     handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datasets/taxi.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/taxi.csv', parse_dates=[0])\n",
    "print(df.head())\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Celda [2]</b> <a class=\"tocSkip\"></a><br>\n",
    "Has hecho un excelente trabajo al cargar los datos usando `parse_dates`. Esto es crucial para el análisis temporal, ya que permite manejar las fechas de manera eficiente y precisa en tus análisis posteriores.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos aseguramos de quitar valores duplicados o ausentes\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso mis fechas a mi indice\n",
    "df.set_index('datetime',inplace=True)\n",
    "\n",
    "# Imprimo si esta en orden cronologico y la info de mi df\n",
    "print(f'Los datos estan en orden cronologico: {df.index.is_monotonic_increasing}')\n",
    "print(df.info())\n",
    "\n",
    "# Trazo el gráfico\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que tenemos dos columnas, la fecha y el numero de ordenes, por como esta el df de head podemos decir que tenemos datos cada 10 minutos. Ya viene con un sort por fecha, las fechas estan en formato de object, 'yyyy-mm-dd'. Las ordenes abarcan del 01 de Marzo 2018 al 31 de Agosto 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remuestreo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos se encuentran en intervalos de 10 minutos, el primer paso sera agruparlos por hora como se indica en el proyecto. Para esto haremos un resampling por hora y una sumatoria. Si usaramos mean me daria el promedio de pedidos cada 10 minutos en una hora. En este caso buscamos la cantidad total de pedidos de taxi por hora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Remuestreo por hora y sumamos todos los pedidos de cada hora.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mresample(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1h\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Remuestreo por hora y sumamos todos los pedidos de cada hora.\n",
    "df = df.resample('1h').sum()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Celda [3]</b> <a class=\"tocSkip\"></a><br>\n",
    "Al realizar el remuestreo por hora y sumar los pedidos, es importante verificar si hay horas sin datos, ya que esto podría afectar el análisis. Considera cómo manejar las horas sin datos para mantener la integridad del análisis temporal.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mplot(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m3\u001b[39m), title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPedidos por hora\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNúmero de pedidos\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFecha\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.plot(figsize=(14, 3), title='Pedidos por hora')\n",
    "plt.ylabel(\"Número de pedidos\")\n",
    "plt.xlabel(\"Fecha\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Celda [4]</b> <a class=\"tocSkip\"></a><br>\n",
    "La visualización de los pedidos por hora está bien lograda. El uso de etiquetas claras y un título descriptivo facilita la interpretación del gráfico, lo cual es esencial para comunicar tus hallazgos de manera efectiva.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Media Movil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos la media movil a lo largo de 6 horas, asi obtenemos 4 secciones por dia y amortiguamos las fluctuaciones pero manteniendo un buen nivel de precisión para los modelos. Usaremos una quincena al azar para visualizar mejor el conjunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mrolling(\u001b[38;5;241m6\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mplot()\n\u001b[1;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mrolling(\u001b[38;5;241m6\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2018-05-01\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2018-05-14\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mplot()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.rolling(6).mean().plot()\n",
    "df.rolling(6).mean()[\"2018-05-01\":\"2018-05-14\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal Decompose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscamos separar la serie en tendencia, estacionalidad y residuo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m decomposed \u001b[38;5;241m=\u001b[39m seasonal_decompose(\u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_orders\u001b[39m\u001b[38;5;124m'\u001b[39m], model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madditive\u001b[39m\u001b[38;5;124m'\u001b[39m, period\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m)\n\u001b[1;32m      2\u001b[0m decomposed\u001b[38;5;241m.\u001b[39mplot()\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39msuptitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSeasonal Decompose\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPedidos por Hora\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m14\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "decomposed = seasonal_decompose(df['num_orders'], model='additive', period=24)\n",
    "decomposed.plot()\n",
    "plt.suptitle('Seasonal Decompose\\nPedidos por Hora', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Celda [6]</b> <a class=\"tocSkip\"></a><br>\n",
    "En el análisis de descomposición estacional, es fundamental interpretar correctamente las componentes de tendencia, estacionalidad y residuo. Comprender estas componentes te permitirá obtener una visión más profunda del comportamiento temporal de los datos.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decomposed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Seasonal Decompose viendo la quincena aleatoria\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mdecomposed\u001b[49m\u001b[38;5;241m.\u001b[39mtrend[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2018-05-01\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2018-05-07\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mplot()\n\u001b[1;32m      4\u001b[0m decomposed\u001b[38;5;241m.\u001b[39mseasonal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2018-05-01\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2018-05-07\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mplot()\n\u001b[1;32m      5\u001b[0m decomposed\u001b[38;5;241m.\u001b[39mresid[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2018-05-01\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2018-05-07\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mplot()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'decomposed' is not defined"
     ]
    }
   ],
   "source": [
    "# Seasonal Decompose viendo la quincena aleatoria\n",
    "\n",
    "decomposed.trend[\"2018-05-01\":\"2018-05-07\"].plot()\n",
    "decomposed.seasonal[\"2018-05-01\":\"2018-05-07\"].plot()\n",
    "decomposed.resid[\"2018-05-01\":\"2018-05-07\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De nuestros graficos podemos ver que:\n",
    "\n",
    "- Empieza a haber una tendencia a la alza, empezando a ser mas notoria a partir del mes de Agosto.\n",
    "- La estacionalidad desaparece a largo plazo.\n",
    "- Dentro de un dia podemos ver horas pico y horas de baja demanda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para creaciond e caracteristicas año, mes, dia y dia de la semana.\n",
    "\n",
    "* En este caso, no incluiremos año debido a que no agrega variabilidad, debido a que todos nuestros valores de año son 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(df, max_lag, rolling_mean_size):\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    #df['year'] = df.index.year\n",
    "    df['month'] = df.index.month\n",
    "    df['day'] = df.index.day\n",
    "    df['dayofweek'] = df.index.dayofweek\n",
    "    df['hour'] = df.index.hour\n",
    "    \n",
    "    for lag in range(1, max_lag + 1):\n",
    "        df['lag_{}'.format(lag)] = df['num_orders'].shift(lag)\n",
    "    \n",
    "    df[\"rolling_mean\"]=df['num_orders'].shift().rolling(rolling_mean_size).mean()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Celda [8]</b> <a class=\"tocSkip\"></a><br>\n",
    "Cuando creas características de retraso (lag), es importante considerar cómo el uso de `dropna()` puede afectar tus datos. Podría eliminar demasiados datos, así que evalúa alternativas para manejar los valores faltantes y así preservar la mayor cantidad de información posible.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corremos nuestra funcion seleccionando un max lag de 4 y rolling mean de 4 arbitrariamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m make_features(\u001b[43mdf\u001b[49m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "make_features(df, 4, 4)\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mcorr()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Celda [10]</b> <a class=\"tocSkip\"></a><br>\n",
    "Calcular la matriz de correlación es un buen paso para identificar relaciones entre las variables. Esto puede informar tus decisiones de modelado al resaltar qué variables podrían ser más predictivas.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Aplicamos un train_test\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_orders\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_orders\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Train test Split con 75% train y 25% test\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Aplicamos un train_test\n",
    "X = df.drop(columns='num_orders')\n",
    "y = df['num_orders']\n",
    "\n",
    "# Train test Split con 75% train y 25% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Celda [12]</b> <a class=\"tocSkip\"></a><br>\n",
    "Has realizado correctamente la separación de los datos en conjuntos de entrenamiento y prueba, lo cual es esencial para evaluar el rendimiento del modelo de manera objetiva. El tamaño de prueba del 25% es adecuado para este propósito.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m\n\u001b[1;32m      2\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[1;32m      3\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m, StandardScaler()),\n\u001b[1;32m      4\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m, LinearRegression())\n\u001b[1;32m      5\u001b[0m ])\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Entrenamos el modelo y medimos el tiempo\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m pipeline\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m, y_train)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Hacemos predicciones\u001b[39;00m\n\u001b[1;32m     11\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Pipeline con modelo y scaler\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "# Entrenamos el modelo y medimos el tiempo\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Hacemos predicciones\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calculamos RMSE\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# 5. Mostramos resultados\n",
    "print(f\"RMSE en conjunto de prueba: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Celda [13]</b> <a class=\"tocSkip\"></a><br>\n",
    "El cálculo del RMSE es correcto, pero parece que hay un error en el uso de la función `root_mean_squared_error`. Deberías usar `mean_squared_error` de `sklearn.metrics` con el parámetro `squared=False` para calcular el RMSE correctamente. Esto asegurará que las evaluaciones de rendimiento sean precisas.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbol de Decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_scorer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Scorer\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m rmse_scorer \u001b[38;5;241m=\u001b[39m \u001b[43mmake_scorer\u001b[49m(root_mean_squared_error, greater_is_better\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Pipeline\u001b[39;00m\n\u001b[1;32m      5\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[1;32m      6\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m, StandardScaler()),\n\u001b[1;32m      7\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m, DecisionTreeRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m))\n\u001b[1;32m      8\u001b[0m ])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'make_scorer' is not defined"
     ]
    }
   ],
   "source": [
    "# Scorer\n",
    "rmse_scorer = make_scorer(root_mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', DecisionTreeRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Hiperparámetros\n",
    "param_grid = {\n",
    "    'model__max_depth': [5, 10, 15, 20, None],\n",
    "    'model__min_samples_split': [2, 5, 10],\n",
    "    'model__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring=rmse_scorer,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Evaluación\n",
    "y_pred = grid_search.predict(X_test)\n",
    "rmse_test = root_mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Resultados\n",
    "print(f\"Mejor RMSE (negativo): {grid_search.best_score_:.2f}\")\n",
    "print(f\"Mejores parámetros: {grid_search.best_params_}\")\n",
    "print(f\"RMSE en conjunto de prueba: {rmse_test:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Celda [14]</b> <a class=\"tocSkip\"></a><br>\n",
    "Has implementado correctamente un `GridSearchCV` para optimizar los hiperparámetros del modelo de árbol de decisión. Este enfoque es crucial para mejorar el rendimiento del modelo al encontrar la mejor combinación de hiperparámetros.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_scorer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Scorer\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m rmse_scorer \u001b[38;5;241m=\u001b[39m \u001b[43mmake_scorer\u001b[49m(root_mean_squared_error, greater_is_better\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Pipeline con escalado + modelo\u001b[39;00m\n\u001b[1;32m      5\u001b[0m rf_pipeline \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[1;32m      6\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m, StandardScaler()),\n\u001b[1;32m      7\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m, RandomForestRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m      8\u001b[0m ])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'make_scorer' is not defined"
     ]
    }
   ],
   "source": [
    "# Scorer\n",
    "rmse_scorer = make_scorer(root_mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# Pipeline con escalado + modelo\n",
    "rf_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', RandomForestRegressor(random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Grid de hiperparámetros para RandomForest\n",
    "param_grid_rf = {\n",
    "    'model__n_estimators': [50, 100, 200],\n",
    "    'model__max_depth': [5, 10, None],\n",
    "    'model__min_samples_split': [2, 5],\n",
    "    'model__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search_rf = GridSearchCV(\n",
    "    rf_pipeline,\n",
    "    param_grid_rf,\n",
    "    cv=3,\n",
    "    scoring=rmse_scorer,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Entrenamiento\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluación\n",
    "y_pred_rf = grid_search_rf.predict(X_test)\n",
    "rmse_test_rf = root_mean_squared_error(y_test, y_pred_rf)\n",
    "\n",
    "# Resultados\n",
    "print(f\"Mejor RMSE (negativo): {grid_search_rf.best_score_:.2f}\")\n",
    "print(f\"Mejores parámetros: {grid_search_rf.best_params_}\")\n",
    "print(f\"RMSE en conjunto de prueba: {rmse_test_rf:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Celda [15]</b> <a class=\"tocSkip\"></a><br>\n",
    "En el modelo de Random Forest, asegúrate de que los hiperparámetros seleccionados realmente mejoran el rendimiento del modelo. Realizar una validación cruzada más exhaustiva podría ayudarte a verificar la estabilidad y robustez de los resultados obtenidos.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_scorer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Scorer\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m rmse_scorer \u001b[38;5;241m=\u001b[39m \u001b[43mmake_scorer\u001b[49m(root_mean_squared_error, greater_is_better\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Pipeline con escalado y modelo\u001b[39;00m\n\u001b[1;32m      5\u001b[0m xgb_pipeline \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[1;32m      6\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m, StandardScaler()),\n\u001b[1;32m      7\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m, XGBRegressor(objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreg:squarederror\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m      8\u001b[0m ])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'make_scorer' is not defined"
     ]
    }
   ],
   "source": [
    "# Scorer\n",
    "rmse_scorer = make_scorer(root_mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# Pipeline con escalado y modelo\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', XGBRegressor(objective='reg:squarederror', random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Grid de hiperparámetros\n",
    "param_grid_xgb = {\n",
    "    'model__n_estimators': [100, 200],\n",
    "    'model__max_depth': [3, 5, 7],\n",
    "    'model__learning_rate': [0.05, 0.1],\n",
    "    'model__subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search_xgb = GridSearchCV(\n",
    "    xgb_pipeline,\n",
    "    param_grid_xgb,\n",
    "    scoring=rmse_scorer,\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Entrenamiento\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones y evaluación\n",
    "y_pred_xgb = grid_search_xgb.predict(X_test)\n",
    "rmse_test_xgb = root_mean_squared_error(y_test, y_pred_xgb)\n",
    "\n",
    "# Resultados\n",
    "print(f\"Mejor RMSE (negativo): {grid_search_xgb.best_score_:.2f}\")\n",
    "print(f\"Mejores parámetros: {grid_search_xgb.best_params_}\")\n",
    "print(f\"RMSE en conjunto de prueba: {rmse_test_xgb:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Celda [16]</b> <a class=\"tocSkip\"></a><br>\n",
    "La implementación del modelo XGBoost y la optimización de sus hiperparámetros es un enfoque sólido para mejorar el rendimiento en tareas de regresión. Bien hecho al incluir múltiples parámetros en el grid search para explorar diferentes configuraciones.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rmse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Diccionario con resultados\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model_results \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModelo\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLinear Regression\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDecision Tree\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXGBoost\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[43mrmse\u001b[49m, rmse_test, rmse_test_rf, rmse_test_xgb]\n\u001b[1;32m      5\u001b[0m }\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Crear DataFrame\u001b[39;00m\n\u001b[1;32m      8\u001b[0m df_resultados \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(model_results)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rmse' is not defined"
     ]
    }
   ],
   "source": [
    "# Diccionario con resultados\n",
    "model_results = {\n",
    "    'Modelo': ['Linear Regression', 'Decision Tree', 'Random Forest', 'XGBoost'],\n",
    "    'RMSE': [rmse, rmse_test, rmse_test_rf, rmse_test_xgb]\n",
    "}\n",
    "\n",
    "# Crear DataFrame\n",
    "df_resultados = pd.DataFrame(model_results)\n",
    "df_resultados.sort_values(by='RMSE').set_index('Modelo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario final</b> <a class=\"tocSkip\"></a><br>\n",
    "¡Muy buen trabajo, Carlos! A lo largo del proyecto, has demostrado fortalezas claras en varias áreas:<br><br>\n",
    "• Carga eficiente de datos con `parse_dates`, facilitando el análisis temporal.<br>\n",
    "• Visualizaciones claras y efectivas que comunican tus hallazgos de manera precisa.<br>\n",
    "• Implementación adecuada de la descomposición estacional para entender el comportamiento de los datos.<br>\n",
    "• Creación de características temporales útiles que mejoran el modelado.<br>\n",
    "• Correcta separación de conjuntos de entrenamiento y prueba para una evaluación objetiva del modelo.<br>\n",
    "• Uso de `GridSearchCV` para optimización de hiperparámetros, mejorando el rendimiento del modelo.<br>\n",
    "• Implementación de múltiples modelos para una comparación exhaustiva.<br>\n",
    "• Evaluación del rendimiento del modelo mediante RMSE, asegurando precisión en las predicciones.<br>\n",
    "• Uso de pipelines para estructurar el flujo de trabajo de manera eficiente.<br>\n",
    "• Exploración de correlaciones entre variables para informar decisiones de modelado.<br>\n",
    "¡Felicidades por tu dedicación y esfuerzo!\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo XGBoost es el que nos da el RMSE mas bajo con un resultado de 24.62.\n",
    "\n",
    "XGBoost es la opción recomendada para ser implementada en producción, ya que ofrece una excelente relación entre precisión y eficiencia. Además, al tratarse de un modelo robusto frente a datos ruidosos y capaz de capturar relaciones no lineales, se adapta bien a problemas de series de tiempo como este."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lista de revisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  \t\n",
    "Jupyter Notebook está abierto.\n",
    "- [ ]  El código no tiene errores\n",
    "- [ ]  Las celdas con el código han sido colocadas en el orden de ejecución.\n",
    "- [ ]  \t\n",
    "Los datos han sido descargados y preparados.\n",
    "- [ ]  Se ha realizado el paso 2: los datos han sido analizados\n",
    "- [ ]  Se entrenó el modelo y se seleccionaron los hiperparámetros\n",
    "- [ ]  Se han evaluado los modelos. Se expuso una conclusión\n",
    "- [ ] La *RECM* para el conjunto de prueba no es más de 48"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
