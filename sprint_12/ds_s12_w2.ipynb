{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7c1f8483",
      "metadata": {
        "id": "7c1f8483"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris, load_breast_cancer, fetch_california_housing,fetch_openml, make_classification\n",
        "from sklearn.linear_model import Lasso, LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.feature_selection import SelectKBest, chi2, RFECV\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a9dd355",
      "metadata": {
        "id": "7a9dd355",
        "outputId": "8a097d0b-0eb1-4c6c-a164-862510f59907"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mrmr_selection\n",
            "  Downloading mrmr_selection-0.2.8-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: jinja2 in /Volumes/Carlos Vallejo SSD/Triple Ten/tripleten-ds/ttds_venv/lib/python3.10/site-packages (from mrmr_selection) (3.1.6)\n",
            "Collecting polars>=0.12.5\n",
            "  Downloading polars-1.29.0-cp39-abi3-macosx_11_0_arm64.whl (31.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m31.1/31.1 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /Volumes/Carlos Vallejo SSD/Triple Ten/tripleten-ds/ttds_venv/lib/python3.10/site-packages (from mrmr_selection) (1.5.1)\n",
            "Requirement already satisfied: category-encoders in /Volumes/Carlos Vallejo SSD/Triple Ten/tripleten-ds/ttds_venv/lib/python3.10/site-packages (from mrmr_selection) (2.6.3)\n",
            "Requirement already satisfied: pandas>=1.0.3 in /Volumes/Carlos Vallejo SSD/Triple Ten/tripleten-ds/ttds_venv/lib/python3.10/site-packages (from mrmr_selection) (2.2.2)\n",
            "Requirement already satisfied: tqdm in /Volumes/Carlos Vallejo SSD/Triple Ten/tripleten-ds/ttds_venv/lib/python3.10/site-packages (from mrmr_selection) (4.67.1)\n",
            "Requirement already satisfied: scipy in /Volumes/Carlos Vallejo SSD/Triple Ten/tripleten-ds/ttds_venv/lib/python3.10/site-packages (from mrmr_selection) (1.15.2)\n",
            "Requirement already satisfied: joblib in /Volumes/Carlos Vallejo SSD/Triple Ten/tripleten-ds/ttds_venv/lib/python3.10/site-packages (from mrmr_selection) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /Volumes/Carlos Vallejo SSD/Triple Ten/tripleten-ds/ttds_venv/lib/python3.10/site-packages (from mrmr_selection) (2.1.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Volumes/Carlos Vallejo SSD/Triple Ten/tripleten-ds/ttds_venv/lib/python3.10/site-packages (from pandas>=1.0.3->mrmr_selection) (2025.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Volumes/Carlos Vallejo SSD/Triple Ten/tripleten-ds/ttds_venv/lib/python3.10/site-packages (from pandas>=1.0.3->mrmr_selection) (2025.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Volumes/Carlos Vallejo SSD/Triple Ten/tripleten-ds/ttds_venv/lib/python3.10/site-packages (from pandas>=1.0.3->mrmr_selection) (2.9.0)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /Volumes/Carlos Vallejo SSD/Triple Ten/tripleten-ds/ttds_venv/lib/python3.10/site-packages (from category-encoders->mrmr_selection) (0.14.4)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /Volumes/Carlos Vallejo SSD/Triple Ten/tripleten-ds/ttds_venv/lib/python3.10/site-packages (from category-encoders->mrmr_selection) (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /Volumes/Carlos Vallejo SSD/Triple Ten/tripleten-ds/ttds_venv/lib/python3.10/site-packages (from scikit-learn->mrmr_selection) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Volumes/Carlos Vallejo SSD/Triple Ten/tripleten-ds/ttds_venv/lib/python3.10/site-packages (from jinja2->mrmr_selection) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /Volumes/Carlos Vallejo SSD/Triple Ten/tripleten-ds/ttds_venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.3->mrmr_selection) (1.17.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /Volumes/Carlos Vallejo SSD/Triple Ten/tripleten-ds/ttds_venv/lib/python3.10/site-packages (from statsmodels>=0.9.0->category-encoders->mrmr_selection) (24.2)\n",
            "Installing collected packages: polars, mrmr_selection\n",
            "Successfully installed mrmr_selection-0.2.8 polars-1.29.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "#!pip install mrmr_selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0c44f840",
      "metadata": {
        "id": "0c44f840"
      },
      "outputs": [],
      "source": [
        "import mrmr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "471d5c2b",
      "metadata": {
        "id": "471d5c2b"
      },
      "source": [
        "# üß† Selecci√≥n de caracter√≠sticas (Feature Selection)\n",
        "\n",
        "## ¬øQu√© es?\n",
        "\n",
        "En ciencia de datos, muchas veces tenemos **muchas columnas (o \"features\")** en una tabla de datos. Pero **no todas las columnas son igual de √∫tiles** para hacer predicciones o entender el problema.\n",
        "\n",
        "La **selecci√≥n de caracter√≠sticas** (en ingl√©s *feature selection*) es el proceso de **elegir solo las columnas m√°s importantes** para nuestro an√°lisis o modelo de machine learning.\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ ¬øPor qu√© es importante?\n",
        "\n",
        "- Mejora la **precisi√≥n** del modelo.\n",
        "- Reduce el **tiempo de entrenamiento** y la complejidad.\n",
        "- Evita que el modelo aprenda \"ruido\" o datos irrelevantes.\n",
        "- Hace que los resultados sean m√°s f√°ciles de interpretar.\n",
        "\n",
        "---\n",
        "\n",
        "## üßë‚Äçüç≥ Ejemplo del mundo real\n",
        "\n",
        "Imagina que eres chef y quieres predecir si a alguien le va a gustar una receta. Tienes datos como:\n",
        "\n",
        "- Edad del comensal  \n",
        "- Si le gusta el picante  \n",
        "- Tama√±o del plato  \n",
        "- Marca del horno usado  \n",
        "- N√∫mero de letras en el nombre del plato  \n",
        "- Ingredientes principales\n",
        "\n",
        "Claramente, algunas columnas no tienen mucha relaci√≥n con el gusto (por ejemplo, la **marca del horno** o el **n√∫mero de letras**). Entonces, al hacer *feature selection*, te quedas solo con las **columnas relevantes**, como si le gusta el picante o los ingredientes.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ ¬øC√≥mo se puede hacer?\n",
        "\n",
        "Existen varias formas de hacer feature selection. Algunas comunes son:\n",
        "\n",
        "- Usar **correlaciones** para ver qu√© columnas se relacionan con la variable que queremos predecir.\n",
        "- Usar modelos como √°rboles de decisi√≥n para ver qu√© columnas considera importantes.\n",
        "- Eliminar columnas con **muchos valores faltantes** o que tienen el **mismo valor en casi todos los registros**.\n",
        "\n",
        "En el siguiente bloque de c√≥digo, veremos un ejemplo pr√°ctico. üëá\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0850e3b",
      "metadata": {
        "id": "c0850e3b",
        "outputId": "61e69240-d159-4b76-f5ae-1c453f868ea9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üéØ Importancia de cada feature:\n",
            "             feature  importancia\n",
            "2  petal length (cm)     0.437380\n",
            "3   petal width (cm)     0.391590\n",
            "0  sepal length (cm)     0.138476\n",
            "1   sepal width (cm)     0.032554\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Cargar un conjunto de datos cl√°sico (flores iris)\n",
        "iris = load_iris()\n",
        "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "df[\"target\"] = iris.target\n",
        "\n",
        "# Crear modelo\n",
        "model = RandomForestClassifier()\n",
        "model.fit(df[iris.feature_names], df[\"target\"])\n",
        "\n",
        "# Mostrar la importancia de cada columna\n",
        "importancias = model.feature_importances_\n",
        "\n",
        "# Crear tabla con resultados\n",
        "importancia_df = pd.DataFrame({\n",
        "    'feature': iris.feature_names,\n",
        "    'importancia': importancias\n",
        "}).sort_values(by='importancia', ascending=False)\n",
        "\n",
        "print(\"üéØ Importancia de cada feature:\")\n",
        "print(importancia_df)\n",
        "\n",
        "# Graficar\n",
        "plt.barh(importancia_df['feature'], importancia_df['importancia'])\n",
        "plt.xlabel(\"Importancia\")\n",
        "plt.title(\"Importancia de las caracter√≠sticas (features)\")\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c8bbfdc",
      "metadata": {
        "id": "0c8bbfdc"
      },
      "source": [
        "# üß† M√©todos de Feature Selection: Con y Sin Interacci√≥n entre Features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ea23c0f",
      "metadata": {
        "id": "2ea23c0f"
      },
      "source": [
        "## üëà 1. M√©todos que **NO tienen en cuenta la interacci√≥n** entre las columnas (features)\n",
        "\n",
        "Estos m√©todos analizan **cada columna por separado**, sin considerar c√≥mo se combinan o influyen entre s√≠. Son simples y r√°pidos.\n",
        "\n",
        "### üîß T√©cnicas comunes:\n",
        "\n",
        "- **Filtro por correlaci√≥n**: Elimina columnas que tienen poca o ninguna relaci√≥n con la variable objetivo.\n",
        "- **Chi-cuadrado (Chi¬≤)**: Eval√∫a si una columna categ√≥rica y la variable objetivo est√°n relacionadas.\n",
        "- **Varianza baja**: Elimina columnas que casi no cambian (por ejemplo, una columna que siempre tiene el mismo valor).\n",
        "- **Selecci√≥n univariante (SelectKBest)**: Prueba cada columna individualmente con una prueba estad√≠stica.\n",
        "\n",
        "üìå √ötiles cuando:\n",
        "- Se quiere una primera limpieza de columnas irrelevantes.\n",
        "- No hay mucho poder computacional."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e1eeff9",
      "metadata": {
        "id": "5e1eeff9"
      },
      "source": [
        "## üéØ SelectKBest: Selecci√≥n univariante de columnas\n",
        "\n",
        "`SelectKBest` es una t√©cnica que **eval√∫a cada columna (feature) de forma individual** y selecciona las mejores seg√∫n una medida estad√≠stica.\n",
        "\n",
        "üëâ Esto es √∫til como primer filtro para eliminar columnas irrelevantes, sin necesidad de entrenar un modelo.\n",
        "\n",
        "---\n",
        "\n",
        "### üß™ Par√°metro `score_func`: ¬øC√≥mo decide qu√© columnas son \"las mejores\"?\n",
        "\n",
        "El par√°metro `score_func` define **la prueba estad√≠stica** que se usar√° para puntuar cada columna. Aqu√≠ est√°n las opciones m√°s comunes y cu√°ndo usarlas:\n",
        "\n",
        "---\n",
        "\n",
        "#### 1. `chi2`: Prueba chi-cuadrado\n",
        "\n",
        "- üìä Tipo de datos: **Features categ√≥ricas o num√©ricas positivas (escaladas)** y **objetivo categ√≥rico**.\n",
        "- üß† ¬øQu√© mide?: Qu√© tan dependiente es una columna respecto a la variable objetivo.\n",
        "- üß™ Ejemplo: Evaluar si el n√∫mero de compras est√° relacionado con el g√©nero (masculino/femenino).\n",
        "- ‚ö†Ô∏è Requiere que los valores sean **mayores o iguales a 0** (usar `MinMaxScaler` si son num√©ricos).\n",
        "\n",
        "---\n",
        "\n",
        "#### 2. `f_classif`: Prueba ANOVA F (para clasificaci√≥n)\n",
        "\n",
        "- üìä Tipo de datos: **Features num√©ricas** y **objetivo categ√≥rico**.\n",
        "- üß† ¬øQu√© mide?: Si las medias de una feature cambian significativamente entre diferentes clases.\n",
        "- üß™ Ejemplo: Evaluar si la altura promedio cambia entre pacientes con o sin enfermedad.\n",
        "- ‚úÖ Muy usado cuando la tarea es **clasificaci√≥n**.\n",
        "\n",
        "---\n",
        "\n",
        "#### 3. `f_regression`: Prueba F para regresi√≥n\n",
        "\n",
        "- üìä Tipo de datos: **Features num√©ricas** y **objetivo num√©rico continuo**.\n",
        "- üß† ¬øQu√© mide?: Cu√°nto contribuye una feature a predecir una variable num√©rica.\n",
        "- üß™ Ejemplo: Ver qu√© columnas ayudan m√°s a predecir el precio de una casa.\n",
        "- ‚úÖ Usado en tareas de **regresi√≥n** (predicci√≥n de valores continuos).\n",
        "\n",
        "---\n",
        "\n",
        "### üß† Recomendaci√≥n general\n",
        "\n",
        "| score_func    | Tarea del modelo | Tipo de variable objetivo | Tipo de features   |\n",
        "|---------------|------------------|----------------------------|--------------------|\n",
        "| `chi2`        | Clasificaci√≥n    | Categ√≥rica                 | Categ√≥ricas o num√©ricas positivas |\n",
        "| `f_classif`   | Clasificaci√≥n    | Categ√≥rica                 | Num√©ricas          |\n",
        "| `f_regression`| Regresi√≥n        | Num√©rica continua          | Num√©ricas          |\n",
        "\n",
        "Usa este m√©todo como **primer paso** antes de entrenar un modelo m√°s complejo üöÄ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2cb8ff1",
      "metadata": {
        "id": "e2cb8ff1",
        "outputId": "afa77e0e-7ca0-4030-9d5c-f413e370f6cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Features seleccionadas (sin interacci√≥n):\n",
            "['mean concavity', 'mean concave points', 'worst perimeter', 'worst area', 'worst concave points']\n"
          ]
        }
      ],
      "source": [
        "# Cargar dataset\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "\n",
        "# Escalar los datos para que chi2 funcione correctamente\n",
        "X_scaled = MinMaxScaler().fit_transform(X)\n",
        "\n",
        "# Aplicar SelectKBest con prueba chi-cuadrado\n",
        "selector = SelectKBest(score_func=chi2, k=5)\n",
        "X_new = selector.fit_transform(X_scaled, y)\n",
        "\n",
        "# Mostrar las columnas seleccionadas\n",
        "selected_features = X.columns[selector.get_support()]\n",
        "print(\"‚úÖ Features seleccionadas (sin interacci√≥n):\")\n",
        "print(selected_features.tolist())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1baaad6e",
      "metadata": {
        "id": "1baaad6e"
      },
      "source": [
        "-----------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49869b1a",
      "metadata": {
        "id": "49869b1a"
      },
      "source": [
        "## ü§ù 2. M√©todos que **S√ç tienen en cuenta la interacci√≥n** entre columnas\n",
        "\n",
        "Estos m√©todos consideran **c√≥mo se combinan varias columnas** para hacer mejores predicciones. Son m√°s avanzados y cercanos al funcionamiento real de los modelos.\n",
        "\n",
        "#### üîß T√©cnicas comunes:\n",
        "\n",
        "- **Lasso (con regularizaci√≥n L1)**: Penaliza columnas menos importantes, dejando solo las esenciales.\n",
        "- **MRMR**:Minima redundancia / Maxima relevancia.\n",
        "- **Modelos de √°rboles (Random Forest, XGBoost)**: Analizan combinaciones de columnas para predecir la variable objetivo.\n",
        "- **RFECV (Recursive Feature Elimination)**: Quita columnas una por una, evaluando el desempe√±o del modelo cada vez con cross validation.\n",
        "\n",
        "üìå √ötiles cuando:\n",
        "- Queremos construir un modelo con alto rendimiento.\n",
        "- Queremos entender **c√≥mo trabajan juntas** las variables para influir en la predicci√≥n.\n",
        "\n",
        "---\n",
        "\n",
        "En los siguientes bloques de c√≥digo veremos un ejemplo de cada tipo. üëá"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dbefcc2",
      "metadata": {
        "id": "1dbefcc2"
      },
      "source": [
        "## üßÆ LASSO: Selecci√≥n de caracter√≠sticas con regresi√≥n\n",
        "\n",
        "### üß† ¬øQu√© es LASSO?\n",
        "\n",
        "LASSO (Least Absolute Shrinkage and Selection Operator) es una t√©cnica de regresi√≥n que **no solo hace predicciones**, sino que tambi√©n **selecciona autom√°ticamente las columnas m√°s importantes** para el modelo.\n",
        "\n",
        "---\n",
        "\n",
        "### üß∞ ¬øC√≥mo funciona?\n",
        "\n",
        "LASSO funciona como un modelo de regresi√≥n tradicional (como predecir el precio de una casa), pero con una diferencia clave:\n",
        "\n",
        "üëâ Le **\"penaliza\"** a las columnas que no ayudan mucho a la predicci√≥n.  \n",
        "üëâ Si una columna no aporta informaci√≥n √∫til, LASSO le pone un **peso de cero**, es decir, la **descarta autom√°ticamente**.\n",
        "\n",
        "Es como si estuvieras en un grupo de trabajo: si alguien no est√° aportando al proyecto, LASSO le dice \"¬°gracias, pero no m√°s!\" üòÑ\n",
        "\n",
        "---\n",
        "\n",
        "### üìâ ¬øPor qu√© es √∫til?\n",
        "\n",
        "- Elimina autom√°ticamente las columnas irrelevantes.\n",
        "- Ayuda a evitar el sobreajuste (cuando el modelo aprende ruido en lugar de patrones reales).\n",
        "- Hace que los modelos sean m√°s simples y f√°ciles de interpretar.\n",
        "\n",
        "---\n",
        "\n",
        "### üìå ¬øCu√°ndo usar LASSO?\n",
        "\n",
        "- Cuando tienes **muchas columnas** y no sabes cu√°les son realmente importantes.\n",
        "- Cuando necesitas **entender mejor** qu√© variables afectan la predicci√≥n.\n",
        "- Cuando quieres un modelo m√°s **simple y r√°pido**.\n",
        "\n",
        "---\n",
        "\n",
        "### üéØ Ejemplo del mundo real\n",
        "\n",
        "Imagina que est√°s tratando de predecir el precio de un apartamento. Tienes columnas como:\n",
        "\n",
        "- N√∫mero de habitaciones  \n",
        "- Piso  \n",
        "- Tama√±o en m¬≤  \n",
        "- N√∫mero de plantas en el edificio  \n",
        "- D√≠a de la semana en que se public√≥ el aviso  \n",
        "- Color de las paredes  \n",
        "\n",
        "Claramente, algunas columnas no ayudan (como el color de las paredes). LASSO se encarga de **detectar y eliminar** esas autom√°ticamente al entrenar el modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a136d845",
      "metadata": {
        "id": "a136d845",
        "outputId": "ea985f86-ed41-4875-c1e6-3c5525ea117f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Features seleccionadas por LASSO:\n",
            "['MedInc', 'HouseAge', 'Latitude']\n",
            "\n",
            "üö´ Features descartadas por LASSO:\n",
            "['AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Longitude']\n"
          ]
        }
      ],
      "source": [
        "# Cargar el dataset California Housing\n",
        "data = fetch_california_housing()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "\n",
        "# Escalar los datos (LASSO lo necesita para que todas las columnas est√©n en la misma escala)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Entrenar un modelo LASSO con penalizaci√≥n alpha\n",
        "lasso = Lasso(alpha=0.1)\n",
        "lasso.fit(X_scaled, y)\n",
        "\n",
        "# Ver qu√© columnas fueron seleccionadas (coeficientes distintos de cero)\n",
        "selected_features = X.columns[lasso.coef_ != 0]\n",
        "discarded_features = X.columns[lasso.coef_ == 0]\n",
        "\n",
        "print(\"‚úÖ Features seleccionadas por LASSO:\")\n",
        "print(selected_features.tolist())\n",
        "\n",
        "print(\"\\nüö´ Features descartadas por LASSO:\")\n",
        "print(discarded_features.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81332dc7",
      "metadata": {
        "id": "81332dc7"
      },
      "source": [
        "-------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fa9c315",
      "metadata": {
        "id": "8fa9c315"
      },
      "source": [
        "## üß† MRMR: Minimum Redundancy Maximum Relevance\n",
        "\n",
        "MRMR es un m√©todo de selecci√≥n de caracter√≠sticas que busca un **equilibrio inteligente** entre:\n",
        "\n",
        "‚úÖ Elegir las columnas **m√°s relevantes** para la variable que queremos predecir  \n",
        "üö´ Evitar columnas que **repiten la misma informaci√≥n** (redundantes)\n",
        "\n",
        "---\n",
        "\n",
        "### üéØ ¬øC√≥mo funciona?\n",
        "\n",
        "Imagina que est√°s eligiendo un grupo de personas para resolver un problema:\n",
        "\n",
        "- Quieres a los que **m√°s saben del tema** (relevancia m√°xima con el objetivo).\n",
        "- Pero tambi√©n quieres que **no digan lo mismo una y otra vez** (redundancia m√≠nima entre ellos).\n",
        "\n",
        "Eso es exactamente lo que hace MRMR:\n",
        "- Eval√∫a **cu√°nto aporta cada columna** a la predicci√≥n.\n",
        "- Pero tambi√©n mide **cu√°nto se parece esa columna a las ya seleccionadas** (para no repetir informaci√≥n).\n",
        "\n",
        "---\n",
        "\n",
        "### üß™ ¬øCu√°ndo usar MRMR?\n",
        "\n",
        "- Cuando tienes **muchas columnas** y no sabes cu√°les usar.\n",
        "- Cuando quieres evitar **columnas duplicadas o que digan lo mismo con otras palabras**.\n",
        "- Cuando est√°s haciendo **clasificaci√≥n o regresi√≥n** y necesitas un subconjunto m√°s limpio y explicativo.\n",
        "\n",
        "---\n",
        "\n",
        "### üåé Ejemplo de la vida real\n",
        "\n",
        "Supongamos que est√°s prediciendo si un paciente tiene diabetes. Tienes columnas como:\n",
        "\n",
        "- Nivel de az√∫car en sangre  \n",
        "- Porcentaje de hemoglobina glucosilada (que tambi√©n mide az√∫car)  \n",
        "- Edad  \n",
        "- Peso  \n",
        "- Presi√≥n arterial  \n",
        "\n",
        "MRMR detectar√≠a que **az√∫car en sangre y hemoglobina glucosilada son muy similares**, y te dejar√≠a solo una. As√≠, el modelo **aprende m√°s con menos columnas**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26fc7b29",
      "metadata": {
        "id": "26fc7b29",
        "outputId": "eaa7a35e-e6ac-41fa-b14c-ab094247ea1a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 79.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Features seleccionadas por MRMR:\n",
            "['thal', 'resting_electrocardiographic_results', 'number_of_major_vessels', 'chest', 'oldpeak']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Cargar un dataset de ejemplo desde openML (Heart Disease)\n",
        "df = fetch_openml(\"heart-statlog\", version=1, as_frame=True).frame\n",
        "# Convertir la variable objetivo en n√∫meros si es categ√≥rica\n",
        "df[\"class\"] = LabelEncoder().fit_transform(df[\"class\"])\n",
        "\n",
        "# Separar features y objetivo\n",
        "X = df.drop(columns=[\"class\"])\n",
        "y = df[\"class\"]\n",
        "\n",
        "# MRMR necesita un solo DataFrame con todas las columnas, incluyendo el target\n",
        "df_full = X.copy()\n",
        "df_full[\"class\"] = y\n",
        "\n",
        "# Aplicar MRMR para seleccionar las 5 mejores columnas\n",
        "selected = mrmr.mrmr_classif(\n",
        "    X=df_full.drop(columns=\"class\"),\n",
        "    y=df_full[\"class\"], K=5\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Features seleccionadas por MRMR:\")\n",
        "print(selected)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35720b0f",
      "metadata": {
        "id": "35720b0f"
      },
      "source": [
        "-------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd224c08",
      "metadata": {
        "id": "dd224c08"
      },
      "source": [
        "## üîç RFECV: Eliminaci√≥n recursiva de caracter√≠sticas con validaci√≥n cruzada\n",
        "\n",
        "`RFECV` es una t√©cnica autom√°tica de selecci√≥n de columnas que:\n",
        "\n",
        "‚úÖ Utiliza un modelo (como `LogisticRegression` o `RandomForest`)  \n",
        "üîÅ Elimina columnas una por una, de forma inteligente  \n",
        "üìà Eval√∫a el rendimiento del modelo en cada paso con validaci√≥n cruzada  \n",
        "üéØ Se queda con el subconjunto de columnas que **mejor desempe√±o da al modelo**\n",
        "\n",
        "---\n",
        "\n",
        "### üß† ¬øC√≥mo funciona?\n",
        "\n",
        "1. Entrena un modelo con **todas las columnas**.\n",
        "2. Elimina la columna **menos importante** (seg√∫n el modelo).\n",
        "3. Repite el proceso hasta quedarse solo con las m√°s √∫tiles.\n",
        "4. Usa **validaci√≥n cruzada** en cada paso para medir qu√© tan bueno es el modelo.\n",
        "5. Devuelve el subconjunto √≥ptimo de columnas.\n",
        "\n",
        "Es como probar diferentes equipos de trabajo y elegir aquel que **trabaja mejor con menos personas**.\n",
        "\n",
        "---\n",
        "\n",
        "### üß™ ¬øCu√°ndo usar RFECV?\n",
        "\n",
        "- Cuando tienes un modelo en mente y quieres que **elija las mejores columnas**.\n",
        "- Cuando quieres **autom√°ticamente balancear simplicidad y rendimiento**.\n",
        "- Cuando te importa que las variables seleccionadas **interact√∫en bien entre s√≠**.\n",
        "\n",
        "---\n",
        "\n",
        "### üåé Ejemplo de la vida real\n",
        "\n",
        "Sup√≥n que est√°s entrenando un modelo para predecir si un correo es spam. Tienes columnas como:\n",
        "\n",
        "- N√∫mero de signos de exclamaci√≥n  \n",
        "- Cantidad de palabras en may√∫sculas  \n",
        "- Presencia de palabras como \"gratis\", \"urgente\", etc.  \n",
        "- Longitud del asunto  \n",
        "- Cantidad de errores ortogr√°ficos  \n",
        "\n",
        "RFECV puede evaluar distintas combinaciones de estas columnas y elegir solo las que realmente ayudan al modelo a identificar correctamente los correos spam, descartando las que confunden o no aportan.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc41a630",
      "metadata": {
        "id": "dc41a630",
        "outputId": "161ddd30-99bb-42e3-c8b9-2d1ad1ddcd7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ N√∫mero √≥ptimo de features: 30\n",
            "üîç Features seleccionadas:\n",
            "['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'symmetry error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst perimeter', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry', 'worst fractal dimension']\n"
          ]
        }
      ],
      "source": [
        "# Cargar dataset de c√°ncer de mama\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "\n",
        "# Escalar los datos (importante para modelos lineales)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Modelo base: regresi√≥n log√≠stica\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Aplicar RFECV con validaci√≥n cruzada estratificada\n",
        "rfecv = RFECV(\n",
        "    estimator=model,\n",
        "    step=1,\n",
        "    cv=StratifiedKFold(5),\n",
        "    scoring='accuracy',\n",
        "    min_features_to_select = 10)\n",
        "rfecv.fit(X_scaled, y)\n",
        "\n",
        "# Mostrar resultados\n",
        "print(f\"‚úÖ N√∫mero √≥ptimo de features: {rfecv.n_features_}\")\n",
        "print(\"üîç Features seleccionadas:\")\n",
        "print(X.columns[rfecv.support_].tolist())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf9fd606",
      "metadata": {
        "id": "bf9fd606"
      },
      "source": [
        "# üß™ Ejercicio pr√°ctico: ¬øVale la pena seleccionar variables?\n",
        "\n",
        "En este ejercicio pondr√°s en pr√°ctica lo aprendido sobre **feature selection** y evaluar√°s su impacto en el entrenamiento de un modelo de machine learning.\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Objetivo\n",
        "\n",
        "Comparar dos modelos de clasificaci√≥n que predicen si un tumor es maligno o benigno:\n",
        "\n",
        "1. Un modelo entrenado con **todas las columnas** disponibles en el dataset.\n",
        "2. Un modelo entrenado **solo con las columnas seleccionadas autom√°ticamente** mediante el m√©todo `RFECV`.\n",
        "\n",
        "---\n",
        "\n",
        "## üß∞ Lo que debes hacer\n",
        "\n",
        "A partir del dataset de c√°ncer de mama (`sklearn.datasets.load_breast_cancer`), realiza lo siguiente:\n",
        "\n",
        "### Paso 1: Cargar y dividir los datos\n",
        "- Separa el dataset en entrenamiento y prueba.\n",
        "\n",
        "### Paso 2: Modelo base (sin selecci√≥n de variables)\n",
        "- Construye un pipeline que incluya:\n",
        "  - Imputaci√≥n (`SimpleImputer`)\n",
        "  - Escalado (`StandardScaler`)\n",
        "  - Modelo (`LogisticRegression`)\n",
        "  - Optimizaci√≥n de hiperpar√°metros con `GridSearchCV`\n",
        "- Entrena el modelo con **todas las columnas** y eval√∫alo.\n",
        "\n",
        "### Paso 3: Feature selection con RFECV\n",
        "- Usa `RFECV` para seleccionar las columnas m√°s √∫tiles bas√°ndote **solo en el conjunto de entrenamiento**.\n",
        "\n",
        "### Paso 4: Modelo con variables seleccionadas\n",
        "- Repite el mismo pipeline anterior pero **usando solo las columnas seleccionadas** por RFECV.\n",
        "\n",
        "### Paso 5: Comparaci√≥n\n",
        "- Compara ambos modelos en t√©rminos de:\n",
        "  - Tiempo de entrenamiento\n",
        "  - Accuracy\n",
        "  - F1-Score\n",
        "  - N√∫mero de columnas usadas\n",
        "- Reflexiona sobre: ¬øvale la pena usar menos columnas? ¬øse pierde desempe√±o?\n",
        "\n",
        "---\n",
        "\n",
        "## üí° Sugerencias\n",
        "\n",
        "- Usa `time.time()` para medir los tiempos.\n",
        "- Aseg√∫rate de aplicar la misma estrategia de imputaci√≥n y escalado en ambos modelos.\n",
        "- Usa `StratifiedKFold` para mantener el equilibrio de clases durante la validaci√≥n cruzada.\n",
        "\n",
        "---\n",
        "\n",
        "## üöÄ Nivel extra (opcional)\n",
        "- Repite el ejercicio con un modelo distinto (por ejemplo `RandomForestClassifier`) y compara los resultados.\n",
        "- Visualiza con una gr√°fica c√≥mo cambia el rendimiento durante la selecci√≥n recursiva con RFECV.\n",
        "\n",
        "---\n",
        "\n",
        "Cuando termines, discute tus hallazgos con tus compa√±eros o escribe una breve conclusi√≥n explicando qu√© aprendiste sobre la selecci√≥n de variables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "efecab24",
      "metadata": {
        "id": "efecab24"
      },
      "outputs": [],
      "source": [
        "# 1. Cargar el dataset\n",
        "# Crear un dataset sint√©tico\n",
        "X, y = make_classification(\n",
        "    n_samples=10000,\n",
        "    n_features=30,\n",
        "    n_informative=10,\n",
        "    n_redundant=10,\n",
        "    n_repeated=0,\n",
        "    n_clusters_per_class=2,\n",
        "    random_state=42,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Crear DataFrame\n",
        "feature_names = [f\"feature_{i}\" for i in range(X.shape[1])]\n",
        "X = pd.DataFrame(X, columns=feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "e7282bf1",
      "metadata": {
        "id": "e7282bf1"
      },
      "outputs": [],
      "source": [
        "# Dividir datos\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "0e663858",
      "metadata": {
        "id": "0e663858"
      },
      "outputs": [],
      "source": [
        "# 3. Pipeline base (sin feature selection)\n",
        "# Preprocesador\n",
        "preprocessor = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "e0d699d9",
      "metadata": {
        "id": "e0d699d9"
      },
      "outputs": [],
      "source": [
        "# Hiperpar√°metros a explorar\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [4, 6, 8]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "c2fca81c",
      "metadata": {
        "id": "c2fca81c",
        "outputId": "8cf96029-eb3b-4b06-eb72-ff016f53fa0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîµ Modelo con todas las variables\n",
            "Accuracy: 0.922\n",
            "F1 Score: 0.9196704428424305\n",
            "Tiempo de entrenamiento: 25.63673996925354 segundos\n"
          ]
        }
      ],
      "source": [
        "# Modelo\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "skf = StratifiedKFold(5,shuffle=True,random_state=0)\n",
        "# Modelo con TODAS las variables\n",
        "pipe_all = Pipeline([\n",
        "    ('prep', preprocessor),\n",
        "    ('clf', GridSearchCV(\n",
        "        estimator=model,\n",
        "        param_grid=param_grid,\n",
        "        cv=skf\n",
        "    ))\n",
        "])\n",
        "\n",
        "start_all = time.time()\n",
        "pipe_all.fit(X_train, y_train)\n",
        "end_all = time.time()\n",
        "\n",
        "# M√©tricas con todas las features\n",
        "y_pred_all = pipe_all.predict(X_test)\n",
        "print(\"üîµ Modelo con todas las variables\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_all))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred_all))\n",
        "print(\"Tiempo de entrenamiento:\", end_all - start_all, \"segundos\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "979f8b8a",
      "metadata": {
        "id": "979f8b8a"
      },
      "outputs": [],
      "source": [
        "# 5. Selecci√≥n de features con RFECV (solo en entrenamiento)\n",
        "\n",
        "# Aplicar preprocesamiento antes de RFECV\n",
        "X_train_prep = preprocessor.fit_transform(X_train)\n",
        "X_test_prep = preprocessor.transform(X_test)\n",
        "\n",
        "# Selecci√≥n de features\n",
        "selector = RFECV(\n",
        "    estimator=RandomForestClassifier(random_state=42),\n",
        "    step=1,\n",
        "    cv=StratifiedKFold(5),\n",
        "    scoring='f1',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "X_train_sel = selector.fit_transform(X_train_prep, y_train)\n",
        "X_test_sel = selector.transform(X_test_prep)\n",
        "selected_features = np.array(feature_names)[selector.support_]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e98bd1d6",
      "metadata": {
        "id": "e98bd1d6",
        "outputId": "565f8553-a815-4cba-ebd0-6c8f8fccdb26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üü¢ Modelo con features seleccionadas\n",
            "Features seleccionadas: [np.str_('feature_0'), np.str_('feature_1'), np.str_('feature_2'), np.str_('feature_3'), np.str_('feature_4'), np.str_('feature_5'), np.str_('feature_6'), np.str_('feature_7'), np.str_('feature_8'), np.str_('feature_9'), np.str_('feature_10'), np.str_('feature_11'), np.str_('feature_12'), np.str_('feature_13'), np.str_('feature_14'), np.str_('feature_15'), np.str_('feature_16'), np.str_('feature_17'), np.str_('feature_18'), np.str_('feature_19')]\n",
            "Accuracy: 0.9245\n",
            "F1 Score: 0.9223650385604113\n",
            "Tiempo de entrenamiento: 36.928837299346924 segundos\n"
          ]
        }
      ],
      "source": [
        "#6. Modelo con features seleccionadas\n",
        "grid_sel = GridSearchCV(\n",
        "    estimator=model,\n",
        "    param_grid={'n_estimators': [50, 100], 'max_depth': [4, 6, 8]},\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "start_sel = time.time()\n",
        "grid_sel.fit(X_train_sel, y_train)\n",
        "end_sel = time.time()\n",
        "\n",
        "# M√©tricas con features seleccionadas\n",
        "y_pred_sel = grid_sel.predict(X_test_sel)\n",
        "print(\"\\nüü¢ Modelo con features seleccionadas\")\n",
        "print(\"Features seleccionadas:\", list(selected_features))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_sel))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred_sel))\n",
        "print(\"Tiempo de entrenamiento:\", end_sel - start_sel, \"segundos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9bdd383",
      "metadata": {},
      "source": [
        "# Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "9671e002",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Cargar el dataset\n",
        "# Crear un dataset sint√©tico\n",
        "X, y = make_classification(\n",
        "    n_samples=10000,\n",
        "    n_features=30,\n",
        "    n_informative=10,\n",
        "    n_redundant=10,\n",
        "    n_repeated=0,\n",
        "    n_clusters_per_class=2,\n",
        "    random_state=42,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Crear DataFrame\n",
        "feature_names = [f\"feature_{i}\" for i in range(X.shape[1])]\n",
        "X = pd.DataFrame(X, columns=feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "8fc6d837",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Divido los datos en conjunto de entrenamiento (75%) y prueba (25%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=42)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "46c24618",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([0, 1]), array([5004, 4996]))"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.unique(y, return_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "4680a961",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejores hiperpar√°metros: {}\n",
            "Mejor score: 0.8162666666666667\n"
          ]
        }
      ],
      "source": [
        "# Creamos un Pipeline con StandardScaler y Regresion Lineal\n",
        "pipeline = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('regressor', LogisticRegression())\n",
        "])\n",
        "\n",
        "param_grid = {}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    pipeline,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Mejores hiperpar√°metros:\", grid_search.best_params_)\n",
        "print(\"Mejor score:\", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "240725a2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar dataset de c√°ncer de mama\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "\n",
        "# Escalar los datos (importante para modelos lineales)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Modelo base: regresi√≥n log√≠stica\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Aplicar RFECV con validaci√≥n cruzada estratificada\n",
        "rfecv = RFECV(\n",
        "    estimator=model,\n",
        "    step=1,\n",
        "    cv=StratifiedKFold(5),\n",
        "    scoring='accuracy',\n",
        "    min_features_to_select = 10)\n",
        "rfecv.fit(X_scaled, y)\n",
        "\n",
        "# Mostrar resultados\n",
        "print(f\"‚úÖ N√∫mero √≥ptimo de features: {rfecv.n_features_}\")\n",
        "print(\"üîç Features seleccionadas:\")\n",
        "print(X.columns[rfecv.support_].tolist())\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ttds_venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
